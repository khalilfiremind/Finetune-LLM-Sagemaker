{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4ad17d",
   "metadata": {},
   "source": [
    "# 03-Deploy: SageMaker Model Deployment\n",
    "\n",
    "## Overview\n",
    "This notebook handles the deployment of our fine-tuned language model to Amazon SageMaker. It uses DJL (Deep Java Library) inference container with VLLM support for optimized inference performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108a6051-2eb6-438f-9932-2578bcf72a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/khaliladib/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from uuid import uuid4\n",
    "import sagemaker\n",
    "from sagemaker.djl_inference.model import DJLModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf18f64",
   "metadata": {},
   "source": [
    "## Key Components\n",
    "\n",
    "### 1. AWS Setup\n",
    "- Uses the \"firemind-sandbox\" AWS profile\n",
    "- Deploys in us-east-1 region\n",
    "- Connects to S3 bucket for model artifacts\n",
    "- Initializes necessary AWS clients and sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e994fd-b08a-4e78-8398-4a046903f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_NAME = \"dev\"\n",
    "REGION_NAME = \"us-east-1\"\n",
    "BUCKET_NAME = \"khalil-adib-bucket\"\n",
    "ARTIFACTS_KEY = \"webinar/dataset/output/webinar-finetine-job-1c56da57-6cbe-453c-8131-76f4bfa2f66d/output/model/\"\n",
    "ARTIFACTS_PATH = f\"s3://{BUCKET_NAME}/{ARTIFACTS_KEY}\"\n",
    "\n",
    "session = boto3.Session(profile_name=PROFILE_NAME, region_name=REGION_NAME)\n",
    "s3_client = session.client('s3')\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf27768-9cd7-422c-9b58-846ad0704f91",
   "metadata": {},
   "source": [
    "### 2. Model Configuration\n",
    "- Deploys model version v011\n",
    "- Uses ml.g5.12xlarge instance for GPU acceleration\n",
    "- Implements VLLM for efficient batch processing\n",
    "- Configures tensor parallelism for model distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c33dd53-377f-4e06-9f36-2c16027eec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = int(time.time())\n",
    "model_name=f\"webinar-model-{model_version}\"\n",
    "\n",
    "endpoint_name=f\"webinar-model-endpoint-VLLM-{model_version}\"\n",
    "\n",
    "instance_type=\"ml.g5.12xlarge\"\n",
    "ROLE = \"arn:aws:iam::026090512591:role/sagemaker-execution-role-SageMakerExecutionRole-lZm8CUm9jqkj\"\n",
    "container_uri = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\"\n",
    "model_data = {\n",
    "    \"S3DataSource\": {\n",
    "        \"S3Uri\": ARTIFACTS_PATH,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8ca6e",
   "metadata": {},
   "source": [
    "### 3. Deployment Settings\n",
    "- Endpoint timeout: 3600 seconds\n",
    "- Batch size: 64\n",
    "- Tensor parallel degree: 2\n",
    "- Uses DJL inference container with LMI 11.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec40e0cb-7780-4c7c-9d62-f29e91b11ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
    "    \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
    "    \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
    "    \"SAGEMAKER_ENV\": \"1\",\n",
    "    \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "    \"TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"vllm\",\n",
    "    \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"64\",\n",
    "    \"TENSOR_PARALLEL_DEGREE\": \"2\"\n",
    "}\n",
    "\n",
    "model = DJLModel(\n",
    "    name=model_name,\n",
    "    image_uri=container_uri,\n",
    "    model_data=model_data,\n",
    "    role=ROLE,\n",
    "    env=config,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a6596",
   "metadata": {},
   "source": [
    "## Process Flow\n",
    "1. Initialize AWS sessions and clients\n",
    "2. Configure model and endpoint names\n",
    "3. Set up DJL model with VLLM support\n",
    "4. Deploy to specified instance type\n",
    "5. Create and configure endpoint\n",
    "\n",
    "## Important Notes\n",
    "- Ensure proper IAM permissions are set\n",
    "- Monitor deployment progress in SageMaker console\n",
    "- Check CloudWatch logs for any issues\n",
    "- Consider instance costs when keeping endpoint running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c73047-a009-4b25-a54b-25bfb5d255e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "llm = model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

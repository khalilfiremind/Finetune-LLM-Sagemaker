{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0f3c4c",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint Inference with Streaming Support\n",
    "\n",
    "This notebook demonstrates how to interact with a SageMaker endpoint for text generation, including both regular and streaming inference capabilities.\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "First, we import the necessary libraries and set up our AWS configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1cfd75-a114-4e36-b8fa-11fb66f7aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08998134",
   "metadata": {},
   "source": [
    "## AWS Configuration\n",
    "\n",
    "Here we configure our AWS session using a specific profile and region. This setup allows us to interact with SageMaker services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70aee0c0-9176-4dcc-b9e2-311f622cfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_name = 'dev'\n",
    "region_name = \"us-east-1\"\n",
    "ENDPOINT_NAME = \"webinar-model-endpoint-VLLM-1747432398\"\n",
    "\n",
    "# Create a Boto3 session using the specified profile\n",
    "boto3_session = boto3.Session(profile_name=profile_name, region_name=region_name)\n",
    "\n",
    "# Initialize the SageMaker session with the Boto3 session\n",
    "sagemaker_runtime = boto3_session.client('sagemaker-runtime', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c301505",
   "metadata": {},
   "source": [
    "## Basic Inference Example\n",
    "\n",
    "This section demonstrates a simple chat completion request to the model. We'll:\n",
    "1. Set up the initial messages\n",
    "2. Configure the generation parameters\n",
    "3. Make the request to the endpoint\n",
    "4. Process the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f6e6a6-e81a-466a-bddd-94542b061fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-140571528865312',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1747433007,\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"Hello! How can I assist you today? Do you have a specific question or topic you'd like to discuss, or are you looking for general information\"},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 20, 'completion_tokens': 30, 'total_tokens': 50}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"please be helpful\"},\n",
    "    {\"role\": \"user\", \"content\": \"hello\"}\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"temperature\": 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    " \n",
    "result = response['Body'].read().decode('utf-8')\n",
    "result = json.loads(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9831133",
   "metadata": {},
   "source": [
    "## Conversation Continuation\n",
    "\n",
    "This example shows how to maintain a conversation by:\n",
    "1. Appending the previous response to the message history\n",
    "2. Adding a new user message\n",
    "3. Making another request to continue the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84491a8-256c-4758-9341-93218590bd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-140668638153600',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1747433104,\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'You\\'re welcome! It was a pleasure to chat with you, even if it was just a simple \"hello\"! If you ever need any help'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 63, 'completion_tokens': 30, 'total_tokens': 93}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(result['choices'][0]['message'])\n",
    "messages.append({\"role\": \"user\", \"content\": \"thank you!\"})\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"temperature\": 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    " \n",
    "result = response['Body'].read().decode('utf-8')\n",
    "result = json.loads(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9bea3",
   "metadata": {},
   "source": [
    "## Streaming Support\n",
    "\n",
    "The `LineIterator` class is a utility for handling streaming responses from the SageMaker endpoint. It:\n",
    "- Parses byte stream input\n",
    "- Handles partial JSON objects that might be split across multiple events\n",
    "- Maintains a buffer to ensure complete messages are processed\n",
    "- Provides an iterator interface for easy consumption of the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccfaa65-501d-4a89-8aa1-9d003e32f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "class LineIterator:\n",
    "    \"\"\"\n",
    "    A helper class for parsing the byte stream input. \n",
    "    \n",
    "    The output of the model will be in the following format:\n",
    "    ```\n",
    "    b'{\"outputs\": [\" a\"]}\\n'\n",
    "    b'{\"outputs\": [\" challenging\"]}\\n'\n",
    "    b'{\"outputs\": [\" problem\"]}\\n'\n",
    "    ...\n",
    "    ```\n",
    "    \n",
    "    While usually each PayloadPart event from the event stream will contain a byte array \n",
    "    with a full json, this is not guaranteed and some of the json objects may be split across\n",
    "    PayloadPart events. For example:\n",
    "    ```\n",
    "    {'PayloadPart': {'Bytes': b'{\"outputs\": '}}\n",
    "    {'PayloadPart': {'Bytes': b'[\" problem\"]}\\n'}}\n",
    "    ```\n",
    "    \n",
    "    This class accounts for this by concatenating bytes written via the 'write' function\n",
    "    and then exposing a method which will return lines (ending with a '\\n' character) within\n",
    "    the buffer via the 'scan_lines' function. It maintains the position of the last read \n",
    "    position to ensure that previous bytes are not exposed again. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord('\\n'):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if 'PayloadPart' not in chunk:\n",
    "                print('Unknown event type:' + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk['PayloadPart']['Bytes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e3066",
   "metadata": {},
   "source": [
    "## Streaming Inference Example\n",
    "\n",
    "This final example demonstrates how to use streaming inference, which:\n",
    "- Provides real-time token generation\n",
    "- Allows for immediate display of model outputs\n",
    "- Uses the same message format but with streaming enabled\n",
    "- Processes the response stream token by token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2f8c61-30d4-414a-a363-ac0bf3b889b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat? I'm here to assist"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"please be helpful\"},\n",
    "    {\"role\": \"user\", \"content\": \"hello\"}\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"max_new_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"stop\": [ \"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\" ]\n",
    "    },\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=ENDPOINT_NAME, \n",
    "    Body=json.dumps(payload), \n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "event_stream = response['Body']\n",
    "\n",
    "for line in LineIterator(event_stream):\n",
    "    resp = json.loads(line)\n",
    "    print(resp.get(\"choices\")[0].get('delta').get('content'), end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
